{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "스킨푸드 비건 라인 화장품 관련 데이터 이용하여 연관어 분석.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXNZyug0tb5a"
      },
      "source": [
        "cd /content/drive/MyDrive/스킨푸드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7kwmRPXJB12"
      },
      "source": [
        "### 키워드 상관관계 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFSnNJAXRDjJ"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvAQARt4tY-I"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df=pd.read_csv('./data/스킨푸드.csv',encoding='cp949')\n",
        "print(df.shape)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2wzcWkstZid"
      },
      "source": [
        "df=df.drop_duplicates()#중복데이터 제거\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAlCJdcttrWB"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiPCi5Sutyx2"
      },
      "source": [
        "!pip install apriori apyori"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHSWk462tnh7"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8L8LKWYtmrQ"
      },
      "source": [
        "korean_stopwords_path='./data/stop_words.txt'\n",
        "\n",
        "with open(korean_stopwords_path,encoding='utf-8')as f:\n",
        "  stopwords=f.readlines()\n",
        "stopwords=[x.strip() for x in stopwords]\n",
        "new_stopwords=['스킨','맑음','비타민','프로폴리스','성분','블랙','케어','추출','비건','인증','사용','크림','릴리','허니','워터','카밍','패드','에센스','카로틴','푸드','피부','세상','담당자','정신','스킨푸드']\n",
        "for st in new_stopwords:\n",
        "  stopwords.append(st)\n",
        "def get_nouns(x):\n",
        "  okt=Okt()\n",
        "  nouns=okt.nouns(x)\n",
        "\n",
        "  nouns=[noun for noun in nouns if noun not in stopwords]\n",
        "  nouns=[noun for noun in nouns if len(noun)>1]\n",
        "  return nouns\n",
        "\n",
        "df['nouns']=df['본문'].apply(lambda x:get_nouns(x))\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osxNBBv7xUJk"
      },
      "source": [
        "#트랜잭션 데이터를 추출합니다.\n",
        "transactions=df['nouns'].tolist()\n",
        "transactions=[transaction for transaction in transactions if transaction]\n",
        "print(transactions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOZHGoesxee5"
      },
      "source": [
        "from apyori import apriori\n",
        "results=list(apriori(transactions,min_support=0.02,min_confidence=0.02,min_list=1.0,max_length=2))\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DROv-Km8ylVX"
      },
      "source": [
        "columns=['source','target','support']\n",
        "df_re=pd.DataFrame(columns=columns)\n",
        "\n",
        "for result in results:\n",
        "  if len(result.items)==2:\n",
        "    items=[x for x in result.items]\n",
        "    row=[items[0], items[1], result.support]\n",
        "    series=pd.Series(row,index=df_re.columns)\n",
        "    df_re=df_re.append(series,ignore_index=True)\n",
        "display(df_re)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUYTH4ugZzQk"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df2=pd.read_csv('./data/비건화장품 아토피.csv',encoding='cp949')\n",
        "print(df2.shape)\n",
        "display(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujDXuR2_a9If"
      },
      "source": [
        "df2=df2.drop_duplicates()#중복데이터 제거\n",
        "print(df2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrO9hgn1bGy8"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Xtel2PbK5Y"
      },
      "source": [
        "korean_stopwords_path='./data/stop_words.txt'\n",
        "\n",
        "with open(korean_stopwords_path,encoding='utf-8')as f:\n",
        "  stopwords=f.readlines()\n",
        "stopwords=[x.strip() for x in stopwords]\n",
        "new_stopwords=['상품','단점','사용','아이','케어','유래','바디','생각','성분','크림','가지','비건','가장','피부','펌프','모나','디자인','첫째','타요','거기','부분','둘째','첫째']\n",
        "for st in new_stopwords:\n",
        "  stopwords.append(st)\n",
        "def get_nouns(x):\n",
        "  okt=Okt()\n",
        "  nouns=okt.nouns(x)\n",
        "\n",
        "  nouns=[noun for noun in nouns if noun not in stopwords]\n",
        "  nouns=[noun for noun in nouns if len(noun)>1]\n",
        "  return nouns\n",
        "\n",
        "df2['nouns']=df2['본문'].apply(lambda x:get_nouns(x))\n",
        "print(df2.shape)\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0-cG6UGbfdd"
      },
      "source": [
        "#트랜잭션 데이터를 추출합니다.\n",
        "transactions=df2['nouns'].tolist()\n",
        "transactions=[transaction for transaction in transactions if transaction]\n",
        "print(transactions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCTSc4n7bmN2"
      },
      "source": [
        "from apyori import apriori\n",
        "results2=list(apriori(transactions,min_support=0.023,min_confidence=0.02,min_list=1.0,max_length=2))\n",
        "print(results2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hekorkxRbtd8"
      },
      "source": [
        "columns=['source','target','support']\n",
        "df_re2=pd.DataFrame(columns=columns)\n",
        "\n",
        "for result in results2:\n",
        "  if len(result.items)==2:\n",
        "    items=[x for x in result.items]\n",
        "    row=[items[0], items[1], result.support]\n",
        "    series=pd.Series(row,index=df_re.columns)\n",
        "    df_re2=df_re2.append(series,ignore_index=True)\n",
        "display(df_re2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVxVtesleVhv"
      },
      "source": [
        "impoer matplotlib.pyplot as plt\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "graph=nx.Graph()\n",
        "graph.add_nodes_from()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6jJXHSi01ae"
      },
      "source": [
        "!pip install networkx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTSAWOrg4iNR"
      },
      "source": [
        "!pip install wordCloud\n",
        "# 글꼴 설치\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aohgusZm1TDq"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import rc\n",
        "font=rc('font',family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "G=nx.Graph()\n",
        "\n",
        "for index,row in node_df.iterrows():\n",
        "  G.add_node(row['node'],nodesize=row['nodesize'])\n",
        "\n",
        "for index,row in df_re2.iterrows():\n",
        "  G.add_weighted_edges_from([(row['source'],row['target'],row['support'])])\n",
        "\n",
        "pos=nx.spring_layout(G,k=0.6,iterations=50)\n",
        "sizes=[G.nodes[node]['nodesize']*25 for node in G]\n",
        "nx.draw(G,pos=pos,node_size=sizes)\n",
        "\n",
        "nx.draw_networkx_labels(G,pos=pos,font_family=font,font_size=25)\n",
        "\n",
        "\n",
        "ax=plt.gca()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiiYpojA2z_H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}